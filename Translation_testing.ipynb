{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQzBONhXSoaa",
        "outputId": "196e6b71-e2d7-4cb6-b276-b58a9b22847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_lines_to_list(path):\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "         return file.read().split('\\n')"
      ],
      "metadata": {
        "id": "Zqpg3fNYZXR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path_ru_text = \"/content/drive/MyDrive/datasets/translation_ru_tat_tests/test_ru.txt\"\n",
        "path_tat_text = \"/content/drive/MyDrive/datasets/translation_ru_tat_tests/test_tat.txt\"\n",
        "path_yandex_ru_tat = \"/content/drive/MyDrive/datasets/translation_ru_tat_tests/yandex_test_ru_tat.txt\"\n",
        "path_yandex_tat_ru = \"/content/drive/MyDrive/datasets/translation_ru_tat_tests/yandex_test_tat_ru.txt\"\n",
        "\n",
        "\n",
        "text_ru = read_file_lines_to_list(path_ru_text)\n",
        "text_tat = read_file_lines_to_list(path_tat_text)\n",
        "translations_yandex_ru_tat = read_file_lines_to_list(path_yandex_ru_tat)\n",
        "translations_yandex_tat_ru = read_file_lines_to_list(path_yandex_tat_ru)"
      ],
      "metadata": {
        "id": "PSaX7TR_jAvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "checkpoint_ru_tat = \"/content/drive/MyDrive/models/model_ru_tat_2epochs\"\n",
        "checkpoint_tat_ru = \"/content/drive/MyDrive/models/model_tat_ru_2epochs\"\n",
        "checkpoint = \"facebook/nllb-200-distilled-600M\"\n",
        "\n",
        "\n",
        "model_ru_tat = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_ru_tat)\n",
        "model_tat_ru = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_tat_ru)\n",
        "model_base = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "\n",
        "from transformers import NllbTokenizerFast\n",
        "\n",
        "tokenizer_ru_tat = NllbTokenizerFast.from_pretrained(checkpoint, src_lang='rus_Cyrl', tgt_lang='tat_Cyrl')\n",
        "tokenizer_tat_ru = NllbTokenizerFast.from_pretrained(checkpoint, src_lang='tat_Cyrl', tgt_lang='rus_Cyrl')"
      ],
      "metadata": {
        "id": "pryoSMyDiq-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ru_tat.cuda()\n",
        "model_tat_ru.cuda()\n",
        "model_base.cuda()"
      ],
      "metadata": {
        "id": "PctduRJ_wICS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "translator_base_ru_tat = pipeline(\"translation\", model=model_base, tokenizer=tokenizer_ru_tat,\n",
        "                                  src_lang='rus_Cyrl', tgt_lang='tat_Cyrl', device=0, num_beams=8, batch_size=BATCH_SIZE)\n",
        "translator_our_ru_tat = pipeline(\"translation\", model=model_ru_tat, tokenizer=tokenizer_ru_tat,\n",
        "                                 src_lang='rus_Cyrl', tgt_lang='tat_Cyrl', device=0, num_beams=8, batch_size=BATCH_SIZE)\n",
        "translator_base_tat_ru = pipeline(\"translation\", model=model_base, tokenizer=tokenizer_tat_ru,\n",
        "                                  src_lang='tat_Cyrl', tgt_lang='rus_Cyrl', device=0, num_beams=8, batch_size=BATCH_SIZE)\n",
        "translator_our_tat_ru = pipeline(\"translation\", model=model_tat_ru, tokenizer=tokenizer_tat_ru,\n",
        "                                 src_lang='tat_Cyrl', tgt_lang='rus_Cyrl', device=0, num_beams=8, batch_size=BATCH_SIZE)\n",
        "\n",
        "def create_batches(data, batch_size=BATCH_SIZE):\n",
        "    return [data[i:i+batch_size] for i in range(0, len(data), batch_size)]\n",
        "\n",
        "text_ru_batches = create_batches(text_ru)\n",
        "text_tat_batches = create_batches(text_tat)\n",
        "\n",
        "translations_base_ru_tat = []\n",
        "translations_our_ru_tat = []\n",
        "translations_base_tat_ru = []\n",
        "translations_our_tat_ru = []\n",
        "\n",
        "print(f\"Total batches: {len(text_ru_batches)}\")\n",
        "\n",
        "for batch in tqdm(text_ru_batches, desc=\"Base ru->tat\"):\n",
        "    results = translator_base_ru_tat(batch)\n",
        "    translations_base_ru_tat.extend([res['translation_text'] for res in results])\n",
        "\n",
        "for batch in tqdm(text_ru_batches, desc=\"Our ru->tat\"):\n",
        "    results = translator_our_ru_tat(batch)\n",
        "    translations_our_ru_tat.extend([res['translation_text'] for res in results])\n",
        "\n",
        "for batch in tqdm(text_tat_batches, desc=\"Base tat->ru\"):\n",
        "    results = translator_base_tat_ru(batch)\n",
        "    translations_base_tat_ru.extend([res['translation_text'] for res in results])\n",
        "\n",
        "for batch in tqdm(text_tat_batches, desc=\"Our tat->ru\"):\n",
        "    results = translator_our_tat_ru(batch)\n",
        "    translations_our_tat_ru.extend([res['translation_text'] for res in results])"
      ],
      "metadata": {
        "id": "wNU8m1VW2h4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_translations_ru_tat = \"/content/drive/MyDrive/utils/translations/translations_2ep_ru_tat.txt\"\n",
        "path_translations_tat_ru = \"/content/drive/MyDrive/utils/translations/translations_2ep_tat_ru.txt\"\n",
        "path_translations_base_ru_tat= \"/content/drive/MyDrive/utils/translations/translations_base_ru_tat.txt\"\n",
        "path_translations_base_tat_ru=\"/content/drive/MyDrive/utils/translations/translations_base_tat_ru.txt\"\n",
        "\n",
        "def save_translations(translations, path):\n",
        "    translations_to_save = '\\n'.join(translations)\n",
        "    with open(path, 'w') as f:\n",
        "        f.write(translations_to_save)\n",
        "\n",
        "save_translations(translations_our_ru_tat, path_translations_ru_tat)\n",
        "save_translations(translations_our_tat_ru, path_translations_tat_ru)\n",
        "save_translations(translations_base_ru_tat, path_translations_base_ru_tat)\n",
        "save_translations(translations_base_tat_ru, path_translations_base_tat_ru)"
      ],
      "metadata": {
        "id": "Kvq6-B52vYoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate sacrebleu\n",
        "\n",
        "from datasets import load_metric\n",
        "import evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "collapsed": true,
        "id": "Z24llsKIVX05",
        "outputId": "fb5c2002-5e15-4da4-a522-8e38bd6b4b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m475.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.32.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m16.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu, evaluate\n",
            "Successfully installed colorama-0.4.6 evaluate-0.4.3 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "sacrebleu = evaluate.load(\"sacrebleu\")\n",
        "chrf = evaluate.load(\"chrf\")"
      ],
      "metadata": {
        "id": "hNz9wmFKY77i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_base_ru_tat = \"/content/drive/MyDrive/utils/translations/translations_base_ru_tat.txt\"\n",
        "path_base_tat_ru = \"/content/drive/MyDrive/utils/translations/translations_base_tat_ru.txt\"\n",
        "path_our_ru_tat = \"/content/drive/MyDrive/utils/translations/translations_2ep_ru_tat.txt\"\n",
        "path_our_tat_ru = \"/content/drive/MyDrive/utils/translations/translations_2ep_tat_ru.txt\"\n",
        "\n",
        "\n",
        "translations_base_ru_tat = read_file_lines_to_list(path_base_ru_tat)\n",
        "translations_base_tat_ru = read_file_lines_to_list(path_base_tat_ru)\n",
        "translations_our_ru_tat = read_file_lines_to_list(path_our_ru_tat)\n",
        "translations_our_tat_ru = read_file_lines_to_list(path_our_tat_ru)"
      ],
      "metadata": {
        "id": "BXgVHmg2YQ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_BLEU_Chrf(model_name, lang_dir, predictions, references):\n",
        "    chrf_result = chrf.compute(\n",
        "      predictions=predictions,\n",
        "      references=references,\n",
        "      word_order=2,\n",
        "      char_order=6\n",
        "    )\n",
        "\n",
        "    sacrebleu_result = sacrebleu.compute(\n",
        "        predictions=predictions,\n",
        "        references=references, tokenize=\"intl\", lowercase=True\n",
        "    )\n",
        "\n",
        "    print(f\"{lang_dir} {model_name}: chrf++ = {round(chrf_result['score'], 3)}, sacreBLEU = {round(sacrebleu_result['score'],3)}\")\n"
      ],
      "metadata": {
        "id": "3N1Gy1DOVe5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_BLEU_Chrf(\"Yandex_model\", \"RU-TT\", translations_yandex_ru_tat, text_tat)\n",
        "print_BLEU_Chrf(\"Base NLLB-200/600M\", \"RU-TT\", translations_base_ru_tat, text_tat)\n",
        "print_BLEU_Chrf(\"Our\", \"RU-TT\", translations_our_ru_tat, text_tat)\n",
        "print()\n",
        "print_BLEU_Chrf(\"Yandex_model\", \"TT-RU\", translations_yandex_tat_ru, text_ru)\n",
        "print_BLEU_Chrf(\"Base NLLB-200/600M\", \"TT-RU\", translations_base_tat_ru, text_ru)\n",
        "print_BLEU_Chrf(\"Our\", \"TT-RU\", translations_our_tat_ru, text_ru)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-teH7gyWfEG",
        "outputId": "12050e36-c4dc-4cbb-d056-5cd03023d471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RU-TT Yandex_model: chrf++ = 35.212, sacreBLEU = 6.45\n",
            "RU-TT Base NLLB-200/600M: chrf++ = 45.004, sacreBLEU = 15.303\n",
            "RU-TT Our: chrf++ = 44.175, sacreBLEU = 16.652\n",
            "\n",
            "TT-RU Yandex_model: chrf++ = 34.561, sacreBLEU = 7.375\n",
            "TT-RU Base NLLB-200/600M: chrf++ = 45.571, sacreBLEU = 20.511\n",
            "TT-RU Our: chrf++ = 43.355, sacreBLEU = 18.964\n"
          ]
        }
      ]
    }
  ]
}